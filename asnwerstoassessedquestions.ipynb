{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC82GvTD1v31LTUYSdXV5s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurali077n/QM2/blob/main/asnwerstoassessedquestions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assessed Questions Option 2\n"
      ],
      "metadata": {
        "id": "r-pmu9srsHcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1\n"
      ],
      "metadata": {
        "id": "rWPxr6ykIoH4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5E5Orwrrzxr",
        "outputId": "a98f2014-86eb-471c-9dac-d23bdf5a157b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The least danceable song has 96 streams.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "spotify_data_url = \"https://storage.googleapis.com/qm2/wk1/spotify-2023.csv\"\n",
        "\n",
        "spotify_df = pd.read_csv(spotify_data_url)\n",
        "\n",
        "least_danceable_song = spotify_df.sort_values(by='danceability_%', ascending=True).iloc[0]\n",
        "\n",
        "streams_str = str(least_danceable_song['streams']).replace(',', '')\n",
        "number_of_streams = int(streams_str)\n",
        "\n",
        "print(f\"The least danceable song has {number_of_streams} streams.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 96"
      ],
      "metadata": {
        "id": "P7pgj1r4ETNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2"
      ],
      "metadata": {
        "id": "83TvWiFgIqPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_traffic-related_death_rate'\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "\n",
        "# Load data from the URL using pandas.read_html with a User-Agent header due to error 403\n",
        "tables = pandas.read_html(url, storage_options=headers)\n",
        "\n",
        "df_fatalities = tables[0]\n",
        "\n",
        "df_fatalities.columns = df_fatalities.columns.str.replace(r'\\[.*\\]', '', regex=True).str.strip()\n",
        "\n",
        "df_fatalities = df_fatalities.rename(columns={'Per 100,000 inhabitants': 'Road fatalities per 100,000 inhabitants', 'Date': 'Year'})\n",
        "\n",
        "df_fatalities['Road fatalities per 100,000 inhabitants'] = pandas.to_numeric(df_fatalities['Road fatalities per 100,000 inhabitants'], errors='coerce')\n",
        "\n",
        "grouped_fatalities = df_fatalities.groupby(['Continent', 'Year'])['Road fatalities per 100,000 inhabitants'].mean()\n",
        "\n",
        "average_fatalities_africa_2021 = grouped_fatalities.loc[('Africa', '2021')]\n",
        "\n",
        "print(f\"The average road fatalities per 100,000 inhabitants in Africa in 2021 is: {average_fatalities_africa_2021:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9hMGKA4ymIU",
        "outputId": "0a146104-b3c4-4415-fbe2-2938a52d97ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average road fatalities per 100,000 inhabitants in Africa in 2021 is: 17.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) 17.48"
      ],
      "metadata": {
        "id": "4hRN5G66EWh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3\n"
      ],
      "metadata": {
        "id": "0Bw7PCuuIr_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#assume we already defined df as in the notebook\n",
        "\n",
        "monthly_avg = df.groupby('Month')['AQI'].mean()\n",
        "\n",
        "print('Monthly Average AQI:')\n",
        "print(monthly_avg)\n",
        "\n",
        "best_month_aqi = monthly_avg.min()\n",
        "best_month = monthly_avg.idxmin()\n",
        "\n",
        "print(f'\\nMonth with the lowest average AQI: {best_month} (AQI: {best_month_aqi:.2f})')\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "monthly_avg.plot(kind='bar', color='skyblue')\n",
        "plt.title('Monthly Average AQI in California, 2020')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average AQI')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "worst_month_aqi = monthly_avg.max()\n",
        "worst_month = monthly_avg.idxmax()\n",
        "\n",
        "percentage_difference = ((worst_month_aqi - best_month_aqi) / best_month_aqi) * 100\n",
        "\n",
        "print(f'\\nMonth with the highest average AQI: {worst_month} (AQI: {worst_month_aqi:.2f})')\n",
        "print(f'The percentage difference between the worst and best months is: {percentage_difference:.1f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jP_jBl961U6C",
        "outputId": "87e2f437-dc95-4a83-cf4c-75265cf583bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1665215872.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#assume we already defined df as in the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmonthly_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Month'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AQI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Monthly Average AQI:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The percentage difference between the worst and best months is: 300.7%"
      ],
      "metadata": {
        "id": "VibaqHNjEZfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "Hy9KcOIgESoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#Assume tweets is defined as in the notebook\n",
        "tweets['polarity'] = tweets['text'].apply(lambda x: nlp(str(x))._.blob.polarity)\n",
        "tweets['subjectivity'] = tweets['text'].apply(lambda x: nlp(str(x))._.blob.subjectivity)\n",
        "\n",
        "user_polarity_sum = tweets.groupby('author_id')['polarity'].sum()\n",
        "\n",
        "most_positive_user_id = user_polarity_sum.idxmax()\n",
        "max_polarity_sum = user_polarity_sum.max()\n",
        "\n",
        "most_negative_user_id = user_polarity_sum.idxmin()\n",
        "min_polarity_sum = user_polarity_sum.min()\n",
        "\n",
        "polarity_difference = round(max_polarity_sum - min_polarity_sum, 3)\n",
        "\n",
        "print(f\"Most positive user (ID): {int(most_positive_user_id)}\")\n",
        "print(f\"Total polarity for most positive user: {max_polarity_sum:.3f}\")\n",
        "print(f\"Most negative user (ID): {int(most_negative_user_id)}\")\n",
        "print(f\"Total polarity for most negative user: {min_polarity_sum:.3f}\")\n",
        "print(f\"The difference in total polarity between the most positive and most negative users is: {polarity_difference}\")"
      ],
      "metadata": {
        "id": "hI9qE2Fl3fqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5"
      ],
      "metadata": {
        "id": "aDBLEAmCKFOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def two_hist(groups,group_labs,xlab, title):\n",
        "\tplt.figure(figsize=(15,6))\n",
        "\n",
        "\tit=-1\n",
        "\tfor var in groups:\n",
        "\t\tit+=1\n",
        "\t\tsample_size=1000\n",
        "\t\tsample_means=[]\n",
        "\t\titerations=10000\n",
        "\n",
        "\t\tfor i in range(0,iterations):\n",
        "\t\t\tsample=var.sample(sample_size, replace=True)\n",
        "\t\t\tsample_mean=sample.mean()\n",
        "\t\t\tsample_means.append(sample_mean)\n",
        "\n",
        "\t\tplt.hist(sample_means, bins=int(iterations/300),edgecolor='white',density=True, label=group_labs[it])\n",
        "\t\tmu, se = norm.fit(sample_means)\n",
        "\t\txmin, xmax = plt.xlim()\n",
        "\t\tx = np.linspace(xmin, xmax, 100)\n",
        "\t\tp = norm.pdf(x, mu, se)\n",
        "\n",
        "\t\tplt.plot(x, p, 'k', linewidth=2)\n",
        "\t\tplt.xlabel(xlab)\n",
        "\t\tplt.title(title)\n",
        "\t\tplt.axvline(var.mean(), color='green', linestyle='solid', linewidth=3, label=f'Population Mean {group_labs[it]}')\n",
        "\t\tif it == 0:\n",
        "\t\t\tplt.axvline(mu-se*3, color='black', linestyle='dashed', linewidth=1.5, label='µ ± 3σ (99.7% CI)')\n",
        "\t\telse:\n",
        "\t\t\tplt.axvline(mu-se*3, color='black', linestyle='dashed', linewidth=1.5)\n",
        "\t\tplt.axvline(mu+se*3, color='black', linestyle='dashed', linewidth=1.5)\n",
        "\t\tplt.legend()\n",
        "\n",
        "\tplt.show()\n",
        "\n",
        "community_social_workers = df[df['occupation'] == 'Community and Social Workers']\n",
        "\n",
        "men_sch = community_social_workers[community_social_workers['sex'] == 1]['sch']\n",
        "women_sch = community_social_workers[community_social_workers['sex'] == 2]['sch']\n",
        "\n",
        "two_hist([men_sch, women_sch], ['Men', 'Women'], 'Years of Schooling', 'Schooling Years Distribution for Community and Social Workers (2013)')"
      ],
      "metadata": {
        "id": "finBxSz-6DWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The answer to the assessed question is:\n",
        "\n",
        "4. women have more years of schooling than men (statistically insignificant)."
      ],
      "metadata": {
        "id": "XFoyEyJ_6URG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6\n"
      ],
      "metadata": {
        "id": "48flX8eXLWpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "black_men_df = df[(df['race'] == 2) & (df['sex'] == 1)]\n",
        "white_women_df = df[(df['race'] == 1) & (df['sex'] == 2)]\n",
        "\n",
        "all_occupations = df['occupation'].unique().tolist()\n",
        "valid_occupations = [occ for occ in all_occupations if occ != '.']\n",
        "\n",
        "occupations_black_men_earn_more = []\n",
        "\n",
        "largest_t_stat = 0\n",
        "occupation_with_largest_gap = ''\n",
        "\n",
        "for occupation in valid_occupations:\n",
        "    bm_income_occ = black_men_df[black_men_df['occupation'] == occupation]['income']\n",
        "    ww_income_occ = white_women_df[white_women_df['occupation'] == occupation]['income']\n",
        "\n",
        "    if len(bm_income_occ) >= 2 and len(ww_income_occ) >= 2:\n",
        "        t_stat = manual_ttest(bm_income_occ, ww_income_occ)\n",
        "\n",
        "        if t_stat > 0:\n",
        "            occupations_black_men_earn_more.append(occupation)\n",
        "            print(f\"Found occupation where black men earn more: {occupation} (t-statistic: {t_stat:.2f})\")\n",
        "\n",
        "            if t_stat > largest_t_stat:\n",
        "                largest_t_stat = t_stat\n",
        "                occupation_with_largest_gap = occupation\n",
        "\n",
        "print(\"\\nOccupations where black men earn more than white women:\")\n",
        "print(occupations_black_men_earn_more)\n",
        "\n",
        "print(f\"\\nOccupation with the largest pay gap where black men earn more: {occupation_with_largest_gap} (t-statistic: {largest_t_stat:.2f})\")"
      ],
      "metadata": {
        "id": "gkTbSV4nA9hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Occupation with the largest pay gap where black men earn more: Transportation and materials moving (t-statistic: 5.73)"
      ],
      "metadata": {
        "id": "AuXLnc3GKdv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7"
      ],
      "metadata": {
        "id": "oM7JgrjrLYCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_model = ols('logwage ~ sch + age + C(sex) + C(union) + C(state) + C(occupation) + C(race, Treatment(reference=3))', data=reg_df).fit()\n",
        "\n",
        "black_vs_hispanic_coef = full_model.params['C(race, Treatment(reference=3))[T.2]']\n",
        "\n",
        "pct_diff = (np.exp(black_vs_hispanic_coef) - 1) * 100\n",
        "\n",
        "p_value = full_model.pvalues['C(race, Treatment(reference=3))[T.2]']\n",
        "\n",
        "print(f\"Percentage difference in log hourly wages (Black vs Hispanic): {pct_diff:.2f}%\")\n",
        "print(f\"P-value for this difference: {p_value:.3f}\")\n",
        "\n",
        "if p_value < 0.01:\n",
        "    print(\"This difference is statistically significant at the 99% confidence level.\")\n",
        "else:\n",
        "    print(\"This difference is NOT statistically significant at the 99% confidence level.\")"
      ],
      "metadata": {
        "id": "FV_fZFXnDyE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Percentage difference in log hourly wages (Black vs Hispanic): -0.13%\n",
        "P-value for this difference: 0.886\n",
        "This difference is NOT statistically significant at the 99% confidence level."
      ],
      "metadata": {
        "id": "f_HJkrsyLn5-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vWNisVxuLrod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8\n"
      ],
      "metadata": {
        "id": "lJauOSicLniN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Ensure df_s is loaded and date column is datetime from previous cells\n",
        "# df_s=pd.read_csv('https://storage.googleapis.com/qm2/wk10/state_data.csv', parse_dates=['date'])\n",
        "df_s['date'] = pd.to_datetime(df_s['date'])\n",
        "\n",
        "# 1. Find the state with the largest increase in minimum wage in the 1990s.\n",
        "# Aggregate to yearly max minwage for better year-on-year comparison, as minimum wage changes are usually annual.\n",
        "df_s_yearly = df_s.groupby(['state', df_s['date'].dt.year])['minwage'].max().reset_index()\n",
        "df_s_yearly.rename(columns={'date': 'year'}, inplace=True)\n",
        "\n",
        "df_1990s_yearly = df_s_yearly[(df_s_yearly['year'] >= 1990) & (df_s_yearly['year'] <= 1999)]\n",
        "\n",
        "df_1990s_yearly = df_1990s_yearly.sort_values(by=['state', 'year'])\n",
        "df_1990s_yearly['minwage_lag'] = df_1990s_yearly.groupby('state')['minwage'].shift(1)\n",
        "df_1990s_yearly['minwage_increase'] = df_1990s_yearly['minwage'] - df_1990s_yearly['minwage_lag']\n",
        "\n",
        "# Drop rows where lag is NaN (first year for each state)\n",
        "df_1990s_yearly = df_1990s_yearly.dropna(subset=['minwage_increase'])\n",
        "\n",
        "# Find the state and year with the largest yearly increase\n",
        "# Check if df_1990s_yearly is empty before calling idxmax\n",
        "if df_1990s_yearly.empty:\n",
        "    print(\"No minimum wage increases found in the 1990s in the provided data.\")\n",
        "    treatment_state_name = None\n",
        "    treatment_year = None\n",
        "else:\n",
        "    max_increase_row_yearly = df_1990s_yearly.loc[df_1990s_yearly['minwage_increase'].idxmax()]\n",
        "    treatment_state_name = max_increase_row_yearly['state']\n",
        "    treatment_year = int(max_increase_row_yearly['year'])\n",
        "    treatment_date_str = f'{treatment_year}-01-01' # Using Jan 1st for the year of treatment\n",
        "    treatment_date_dt = pd.to_datetime(treatment_date_str)\n",
        "\n",
        "\n",
        "if treatment_state_name is not None:\n",
        "    print(f\"1. Treatment Group (state with largest minwage increase in 1990s): {treatment_state_name.title()}\")\n",
        "    print(f\"   Approximate Treatment Year: {treatment_year}\")\n",
        "\n",
        "    # 2. Set a 5 year window on either side of the treatment date\n",
        "    window_years = 5\n",
        "    start_year = treatment_year - window_years\n",
        "    end_year = treatment_year + window_years\n",
        "\n",
        "    print(f\"2. Analysis Window: {start_year} to {end_year} (5 years either side of {treatment_year})\")\n",
        "\n",
        "    # Filter data for the treatment and control group within the specified window\n",
        "    control_state_name = 'arizona'\n",
        "    did_assessed = df_s[(df_s['state'].isin([treatment_state_name, control_state_name])) &\n",
        "                        (df_s['date'].dt.year >= start_year) &\n",
        "                        (df_s['date'].dt.year <= end_year)].copy()\n",
        "\n",
        "    # Create Difference-in-Differences variables\n",
        "    did_assessed['post'] = np.where(did_assessed['date'] >= treatment_date_dt, 1, 0)\n",
        "    did_assessed['treatment'] = np.where(did_assessed['state'] == treatment_state_name, 1, 0)\n",
        "    did_assessed['post_treatment'] = did_assessed['post'] * did_assessed['treatment']\n",
        "\n",
        "    # Diagnostic prints for NaN values\n",
        "    print(f\"Shape of did_assessed before dropping NaNs: {did_assessed.shape}\")\n",
        "    print(f\"NaN counts before dropping NaNs:\\n{did_assessed.isnull().sum()}\")\n",
        "\n",
        "    # Check if gdp is entirely missing for this subset\n",
        "    gdp_missing_entirely = did_assessed['gdp'].isnull().all()\n",
        "\n",
        "    regression_formula = 'unemployment ~ cpi + post + treatment + post_treatment'\n",
        "    if not gdp_missing_entirely:\n",
        "        regression_formula = 'unemployment ~ gdp + ' + regression_formula\n",
        "        print(\"\\nNote: GDP data is available and will be included in the regression.\")\n",
        "    else:\n",
        "        print(\"\\nWarning: GDP data is entirely missing for the selected states and time window. Proceeding with regression *without* GDP control, but *with* CPI.\")\n",
        "\n",
        "\n",
        "    # Ensure all regression variables are present and not null\n",
        "    # Adjust regression_vars based on whether gdp is included\n",
        "    regression_vars = ['unemployment', 'cpi', 'post', 'treatment', 'post_treatment']\n",
        "    if not gdp_missing_entirely:\n",
        "        regression_vars.append('gdp')\n",
        "\n",
        "    initial_rows = len(did_assessed)\n",
        "    did_assessed_for_ols = did_assessed.dropna(subset=regression_vars).copy() # Use a copy to avoid SettingWithCopyWarning\n",
        "    filtered_rows = len(did_assessed_for_ols)\n",
        "\n",
        "    print(f\"Initial rows for DiD analysis: {initial_rows}\")\n",
        "    print(f\"Rows after dropping NaNs for regression variables ({', '.join(regression_vars)}): {filtered_rows}\")\n",
        "\n",
        "\n",
        "    # 3. Make a parallel trends plot using Arizona as a control group\n",
        "    print(\"\\n3. Parallel Trends Plot:\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.lineplot(data=did_assessed_for_ols, x='date', y='unemployment', hue='state') # Use did_assessed_for_ols for plotting\n",
        "    plt.axvline(treatment_date_dt, color='black', linestyle='dashed', label=f'{treatment_state_name.title()} Minimum Wage Increase ({treatment_year})')\n",
        "    plt.title(f'Unemployment in {control_state_name.title()} and {treatment_state_name.title()} ({start_year}-{end_year})')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Unemployment Rate')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # 4. Control for the cost of living using the CPI variable.\n",
        "    # 5. Run a difference in differences model.\n",
        "    print(\"\\n5. Difference-in-Differences Model Results (controlling for CPI, and potentially GDP):\")\n",
        "\n",
        "    if not did_assessed_for_ols.empty:\n",
        "        did_model_assessed = ols(regression_formula, data=did_assessed_for_ols).fit()\n",
        "        print(did_model_assessed.summary())\n",
        "\n",
        "        print(\"\\n--- Interpretation of Results ---\")\n",
        "        # Extract post_treatment coefficient and p-value for the DiD estimator\n",
        "        post_treatment_coef = did_model_assessed.params['post_treatment']\n",
        "        post_treatment_pvalue = did_model_assessed.pvalues['post_treatment']\n",
        "\n",
        "        print(f\"The Difference-in-Differences estimator (post_treatment coefficient) is: {post_treatment_coef:.3f}\")\n",
        "        print(f\"The p-value for the DiD estimator is: {post_treatment_pvalue:.3f}\")\n",
        "\n",
        "        # Answer the assessed question regarding percentage change and statistical significance\n",
        "        # The coefficient directly represents the change in unemployment rate in percentage points.\n",
        "        is_significant = post_treatment_pvalue < 0.05 # Using a common alpha level of 0.05\n",
        "\n",
        "        print(f\"\\nResult: The introduction of a minimum wage increase in {treatment_state_name.title()} resulted in an approximate {post_treatment_coef:.2f} percentage point change in unemployment relative to {control_state_name.title()}.\")\n",
        "        if is_significant:\n",
        "            print(f\"This difference is statistically significant (p < 0.05).\")\n",
        "        else:\n",
        "            print(f\"This difference is not statistically significant (p >= 0.05).\")\n",
        "\n",
        "        print(f\"\\nSpecifically, a 1 unit increase in `post_treatment` (i.e., being in {treatment_state_name.title()} during the post-treatment period) is associated with a {post_treatment_coef:.2f} percentage point change in the unemployment rate, after controlling for CPI and other included variables.\")\n",
        "    else:\n",
        "        print(\"Cannot run OLS model: The filtered DataFrame for DiD analysis is empty after dropping missing values. This means there's no complete data for the selected variables and time period.\")\n",
        "        print(f\"Specifically, even after potentially excluding GDP, there might be missing data for other variables like 'cpi' for {treatment_state_name.title()} or {control_state_name.title()} within the years {start_year}-{end_year}.\")\n",
        "else:\n",
        "    print(\"Could not identify a treatment state from the 1990s with a minimum wage increase or the data is insufficient.\")"
      ],
      "metadata": {
        "id": "rnAU65iIF-Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Difference-in-Differences estimator (post_treatment coefficient) is: -1.196\n",
        "The p-value for the DiD estimator is: 0.000\n",
        "\n",
        "Result: The introduction of a minimum wage increase in Iowa resulted in an approximate -1.20 percentage point change in unemployment relative to Arizona.\n",
        "This difference is statistically significant (p < 0.05).\n",
        "\n",
        "Specifically, a 1 unit increase in `post_treatment` (i.e., being in Iowa during the post-treatment period) is associated with a -1.20 percentage point change in the unemployment rate, after controlling for CPI and other included variables."
      ],
      "metadata": {
        "id": "6f0hUd1EGDQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9"
      ],
      "metadata": {
        "id": "SN_3HRVCLxTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_df = drinking.assign(threshold=(drinking[\"agecell\"] > 0).astype(int))\n",
        "model_mva_quad = smf.wls(\"mva ~ agecell + I(agecell**2) + threshold + agecell:threshold + I(agecell**2):threshold\", rdd_df).fit()\n",
        "\n",
        "print(model_mva_quad.summary())\n",
        "\n",
        "# The treatment effect at the threshold is the coefficient of 'threshold'\n",
        "treatment_effect_mva = model_mva_quad.params[\"threshold\"]\n",
        "print(f\"\\nThe treatment effect on motor vehicle accidents (coefficient of 'threshold') is: {treatment_effect_mva:.4f}\")"
      ],
      "metadata": {
        "id": "D0xc_3PZIdtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.6629"
      ],
      "metadata": {
        "id": "oBzTx5OfId8M"
      }
    }
  ]
}